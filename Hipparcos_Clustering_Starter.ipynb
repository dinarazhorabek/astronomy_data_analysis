{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78cf2824",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸŒŒ Hipparcos Stellar Clustering â€” Starter Notebook\n",
    "\n",
    "This notebook helps you cluster **real stars** from the **Hipparcos** mission using features like **color index (Bâ€“V)**, **absolute magnitude (Mv)**, and **distance** (from parallax).\n",
    "Itâ€™s designed to be clean, reproducible, and portfolio-ready.\n",
    "\n",
    "**What youâ€™ll do:**\n",
    "1. Load Hipparcos data (CSV or FITS converted to CSV).\n",
    "2. Engineer features: distance (pc), absolute magnitude, color index.\n",
    "3. Explore with an HR diagram (Bâ€“V vs Mv).\n",
    "4. Cluster stars (KMeans; optional DBSCAN) and visualize results.\n",
    "5. Profile clusters and save outputs.\n",
    "\n",
    "> Tip: Start with **~10kâ€“50k rows** for speed. You can scale up later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b18a0",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“¦ Setup\n",
    "\n",
    "Run the next cell once to install packages if needed (comment it out if already installed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20901752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install pandas numpy scikit-learn matplotlib plotly seaborn\n",
    "# Optional if you plan to query ESA archives directly:\n",
    "# !pip install astroquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Nice plotting defaults\n",
    "plt.rcParams[\"figure.figsize\"] = (7,5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "sns.set_context(\"notebook\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10682f7",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“¥ Load Hipparcos Data\n",
    "\n",
    "Place your Hipparcos CSV next to this notebook and set the filename below.  \n",
    "Typical useful columns (names differ by source):\n",
    "- **Parallax**: `Plx`, `parallax`, `parallax_mas` (milliarcseconds)\n",
    "- **Apparent V Magnitude**: `Vmag`, `phot_g_mean_mag` (Gaia), etc.\n",
    "- **Color index**: `B-V`, `B_V`, `bp_rp` (Gaia alternative)\n",
    "\n",
    "If your file has different column names, fill in the mapping in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ”§ EDIT THIS: your local CSV path\n",
    "DATA_PATH = \"hipparcos_sample.csv\"  # e.g., 'hipparcos.csv' or a subset CSV\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try to auto-detect common column names, then let you override if needed.\n",
    "\n",
    "def pick_first(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "col_parallax = pick_first(df_raw, [\"Plx\", \"parallax\", \"parallax_mas\", \"plx\"])\n",
    "col_vmag     = pick_first(df_raw, [\"Vmag\", \"VmagH\", \"Vmagnitude\", \"vmag\", \"VmagHip\"])\n",
    "col_bv       = pick_first(df_raw, [\"B-V\", \"B_V\", \"BV\", \"bv\"])\n",
    "\n",
    "print(\"Detected columns:\")\n",
    "print(\"  parallax:\", col_parallax)\n",
    "print(\"  Vmag    :\", col_vmag)\n",
    "print(\"  B-V     :\", col_bv)\n",
    "\n",
    "# If any are None, set them manually here, e.g.:\n",
    "# col_parallax = \"Plx\"\n",
    "# col_vmag = \"Vmag\"\n",
    "# col_bv = \"B-V\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae76921",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ§® Feature Engineering\n",
    "\n",
    "We compute:\n",
    "- **Distance** in parsecs: `distance_pc = 1000 / parallax_mas`\n",
    "- **Absolute magnitude (Mv)** from apparent magnitude and distance:\n",
    "  \\[ M = m - 5 \\log_{10}(d/10) \\]\n",
    "- Keep a clean **color index (Bâ€“V)**\n",
    "\n",
    "We also filter physically implausible or low-quality rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Basic sanity checks\n",
    "missing_cols = [name for name in [col_parallax, col_vmag] if name is None]\n",
    "if missing_cols:\n",
    "    raise ValueError(\"Missing required column mapping. Please set col_parallax and col_vmag.\")\n",
    "\n",
    "# Rename working columns to standard names\n",
    "df = df.rename(columns={\n",
    "    col_parallax: \"parallax_mas\",\n",
    "    col_vmag: \"Vmag\",\n",
    "    **({col_bv: \"B_V\"} if col_bv else {})\n",
    "})\n",
    "\n",
    "# Clean parallax (must be > 0 to compute distance); cap extreme values\n",
    "df = df[pd.to_numeric(df[\"parallax_mas\"], errors=\"coerce\") > 0].copy()\n",
    "df[\"parallax_mas\"] = df[\"parallax_mas\"].astype(float)\n",
    "\n",
    "# Distance in parsecs\n",
    "df[\"distance_pc\"] = 1000.0 / df[\"parallax_mas\"]\n",
    "\n",
    "# Absolute magnitude (Mv)\n",
    "df[\"Mv\"] = df[\"Vmag\"] - 5 * (np.log10(df[\"distance_pc\"]) - 1)\n",
    "\n",
    "# If Bâ€“V not present, keep it as NaN (we can still cluster on Mv + distance or add other bands)\n",
    "if \"B_V\" in df.columns:\n",
    "    df[\"B_V\"] = pd.to_numeric(df[\"B_V\"], errors=\"coerce\")\n",
    "\n",
    "# Quality & plausibility filters (you can relax/tighten as needed)\n",
    "df = df[(df[\"distance_pc\"] > 0) & (df[\"distance_pc\"] < 5000)]  # within 5 kpc to avoid extremes\n",
    "df = df[(df[\"Mv\"] > -10) & (df[\"Mv\"] < 20)]                    # plausible absolute magnitudes\n",
    "\n",
    "# Drop rows missing key features\n",
    "key_feats = [\"Mv\", \"distance_pc\"]\n",
    "if \"B_V\" in df.columns:\n",
    "    key_feats.append(\"B_V\")\n",
    "df = df.dropna(subset=key_feats).copy()\n",
    "\n",
    "print(\"After cleaning:\", df.shape)\n",
    "df[key_feats].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedf6f9",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“ˆ Hertzsprungâ€“Russell (HR) Diagram\n",
    "\n",
    "Classic astronomy plot: **x = Bâ€“V (color)**, **y = Mv (absolute magnitude)** (note: y-axis inverted).\n",
    "If Bâ€“V is missing, weâ€™ll plot Mv vs distance as a sanity check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74cfc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "has_bv = \"B_V\" in df.columns and df[\"B_V\"].notna().any()\n",
    "\n",
    "if has_bv:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(df[\"B_V\"], df[\"Mv\"], s=5, alpha=0.5)\n",
    "    ax.set_xlabel(\"B - V (color index)\")\n",
    "    ax.set_ylabel(\"Absolute Magnitude (Mv)\")\n",
    "    ax.invert_yaxis()  # brighter at the top\n",
    "    ax.set_title(\"HR Diagram (Hipparcos)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(df[\"distance_pc\"], df[\"Mv\"], s=5, alpha=0.5)\n",
    "    ax.set_xlabel(\"Distance (pc)\")\n",
    "    ax.set_ylabel(\"Absolute Magnitude (Mv)\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(\"Mv vs Distance (Bâ€“V not available)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a073973",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ§± Prepare Features & Scale\n",
    "\n",
    "Weâ€™ll use the most informative physical features available:\n",
    "- If Bâ€“V exists: **[Bâ€“V, Mv, log10(distance)]**\n",
    "- Else: **[Mv, log10(distance)]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be892f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [\"Mv\", \"distance_pc\"]\n",
    "if has_bv:\n",
    "    features = [\"B_V\", \"Mv\", \"distance_pc\"]\n",
    "\n",
    "X = df[features].copy()\n",
    "# Log-scale distance helps\n",
    "X[\"log10_distance\"] = np.log10(X[\"distance_pc\"])\n",
    "X = X.drop(columns=[\"distance_pc\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Feature matrix shape:\", X_scaled.shape)\n",
    "print(\"Features used:\", list(X.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70746307",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ”» PCA (for visualization only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c456086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9464185",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ”§ KMeans: Elbow & Silhouette\n",
    "\n",
    "Weâ€™ll try cluster counts from 2 to 8 and inspect the elbow and silhouette scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f59a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inertias = []\n",
    "sils = []\n",
    "ks = range(2, 9)\n",
    "\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, n_init=\"auto\", random_state=42)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    inertias.append(km.inertia_)\n",
    "    sils.append(silhouette_score(X_scaled, labels))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(ks), inertias, 'o-')\n",
    "ax.set_xlabel(\"k (clusters)\")\n",
    "ax.set_ylabel(\"Inertia\")\n",
    "ax.set_title(\"Elbow Plot\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(ks), sils, 'o-')\n",
    "ax.set_xlabel(\"k (clusters)\")\n",
    "ax.set_ylabel(\"Silhouette Score\")\n",
    "ax.set_title(\"Silhouette vs k\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc5ca5",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… Fit Final KMeans (choose k)\n",
    "\n",
    "Set your chosen `k_final` below after inspecting the elbow/silhouette plots (often 3â€“5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_final = 3  # ðŸ”§ change if needed\n",
    "km = KMeans(n_clusters=k_final, n_init=\"auto\", random_state=42)\n",
    "df[\"cluster_km\"] = km.fit_predict(X_scaled)\n",
    "\n",
    "print(df[\"cluster_km\"].value_counts().sort_index())\n",
    "df.groupby(\"cluster_km\")[[\"Mv\"] + ([\"B_V\"] if has_bv else [])].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HR diagram colored by clusters (if Bâ€“V available)\n",
    "if has_bv:\n",
    "    fig, ax = plt.subplots()\n",
    "    sc = ax.scatter(df[\"B_V\"], df[\"Mv\"], c=df[\"cluster_km\"], s=6, alpha=0.7, cmap=\"viridis\")\n",
    "    ax.set_xlabel(\"B - V (color index)\")\n",
    "    ax.set_ylabel(\"Absolute Magnitude (Mv)\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(\"HR Diagram colored by KMeans clusters\")\n",
    "    plt.colorbar(sc, ax=ax, label=\"cluster\")\n",
    "    plt.show()\n",
    "\n",
    "# PCA scatter\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(X_pca[:,0], X_pca[:,1], c=df[\"cluster_km\"], s=6, alpha=0.7, cmap=\"viridis\")\n",
    "ax.set_xlabel(\"PCA 1\")\n",
    "ax.set_ylabel(\"PCA 2\")\n",
    "ax.set_title(\"PCA projection colored by KMeans clusters\")\n",
    "plt.colorbar(sc, ax=ax, label=\"cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cff765",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸŒ€ Optional: DBSCAN (density-based)\n",
    "\n",
    "Try DBSCAN if you suspect non-spherical clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f086d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You may need to tune eps & min_samples. Start small, increase gradually.\n",
    "eps = 0.6\n",
    "min_samples = 15\n",
    "\n",
    "db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "labels_db = db.fit_predict(X_scaled)\n",
    "df[\"cluster_db\"] = labels_db  # -1 = noise\n",
    "\n",
    "print(\"DBSCAN label counts:\")\n",
    "print(pd.Series(labels_db).value_counts().sort_index())\n",
    "\n",
    "# Visualize PCA with DBSCAN labels\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(X_pca[:,0], X_pca[:,1], c=labels_db, s=6, alpha=0.7, cmap=\"tab10\")\n",
    "ax.set_xlabel(\"PCA 1\")\n",
    "ax.set_ylabel(\"PCA 2\")\n",
    "ax.set_title(f\"PCA projection colored by DBSCAN (eps={eps}, min_samples={min_samples})\")\n",
    "plt.colorbar(sc, ax=ax, label=\"cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba21e2a",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ’¾ Save Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e972e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUT_CSV = \"hipparcos_clustered.csv\"\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Saved clustered dataset to {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f92edb2",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ§­ Interpreting Clusters (Quick Guide)\n",
    "\n",
    "- **Lower Mv (top of HR diagram) = intrinsically brighter** stars.\n",
    "- **Higher Bâ€“V = redder/cooler**; **Lower Bâ€“V = bluer/hotter**.\n",
    "- Expect clusters roughly corresponding to:\n",
    "  - **Main sequence** (diagonal band)\n",
    "  - **Red giants** (upper-right)\n",
    "  - **White dwarfs** (lower-left; low luminosity but blue)\n",
    "\n",
    "Use `groupby(\"cluster_km\").mean()` and compare typical Bâ€“V / Mv ranges to label your clusters in a table.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}